{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "[[1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# initialize empty tensor \n",
    "\n",
    "tensor1 = torch.ones(1,3, dtype=torch.int)\n",
    "print(tensor1.size())\n",
    "print(tensor1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### VIDEO 2 ######################################################\n",
    "#####################3       TENSOR BASICS ##########################################\n",
    "\n",
    "\n",
    "\n",
    "# convert a numpy array to tensor \n",
    "torch.tensor(any  array)\n",
    "\n",
    "tensor_1 has same size as tensor_2 then we can add these two element wise as \n",
    "tensor_1.add_(tensor_2)\n",
    "if we remove underscore here then it wont be inplace rather it would return the answer to another variable \n",
    "\n",
    "\n",
    "in pytorch every function with trailing underscore _ will do an inplace operation \n",
    "\n",
    "\n",
    "\n",
    "view will reshape the tensor \n",
    "\n",
    "y = x.view(dims)\n",
    "-1 can be used to get the remaining shape of the array \n",
    "view can not be done inplace \n",
    "\n",
    "\n",
    "convert a tensor to numpy array directly using .numpy()\n",
    "\n",
    "a = torch.rand(1)\n",
    "b = a.numpy()\n",
    "print(type(b))\n",
    "\n",
    "convert numpy array to torch tensor using torch.from_numpy()\n",
    "\n",
    "a = np.array(1,1)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "these last two operations will save the changes for both as both are located in same location \n",
    "\n",
    "\n",
    "check if gpu is available or not \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.ones(5, device = device)\n",
    "or torch.ones(5).to(device)\n",
    "\n",
    "\n",
    "numpy can only handle cpu tensor so we can not convert a gpu tensor to numpy array we first would have to move it to cpu \n",
    "bydefault pytorch creates a tensor on cpu, unless specifically mentioned to create it on gpu \n",
    "\n",
    "\n",
    "can shift to cpu using -> .to(\"cpu\")\n",
    "\n",
    "by default for a tensor created the required_grad = false, but we can set it to true while creation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################   GRADIENT WITH AUTOGRAD #####################################333\n",
    "\n",
    "\n",
    "describe a tensor with required_grad = True and then that variable will be put in graph which means it gradient will be tr\n",
    "tracked and computed. so every operation using that variable will be assigned to gradient_fn so that during back \n",
    "prop it can be differentiated \n",
    "\n",
    "\n",
    "x = np.rand(1,requires_grad=True)\n",
    "y = x+1\n",
    "y.backward()  # dy/dx\n",
    "\n",
    "and now when we do x.grad we can get the gradients \n",
    "\n",
    "done in background using jacobian\n",
    "\n",
    "so for .backward() will work on scalar values but if lets say for x.backward() x is a vector then we need to \n",
    "pass another vector of same size as x in the backward like x.(backward(torch.tensor([x.size], dtype=torch.float32)))\n",
    "\n",
    "\n",
    "to prevent gradient tracking for variables we can do this in 3 ways \n",
    "\n",
    "1. x.requires_grad_(False) or x.requires_grad = False \n",
    "\n",
    "2. x.detach()  # detaches the tensor from the graph \n",
    "\n",
    "3. with torch.no_grad():\n",
    "    x. ....\n",
    "    \n",
    "    \n",
    "x.grad.zero_() will zeros the gradients and prevent from accumulating the gradients \n",
    "\n",
    "empty the gradients before calculating the next batch of gradients, as they will accumulate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################33    backpropagation ########################################\n",
    "\n",
    "process \n",
    "1. forward pass where we compute loss  (model output)\n",
    "2. compute local gradients (pytorch does it automatically)\n",
    "3. backward pass compute dloss/dweights by chain rule in backward fashion  (.backward()) \n",
    "\n",
    "so loss.backward() will compute the backward pass that is calculate the gradient using backprop these gradient will be \n",
    "used in the next step by optimizer to update the weights \n",
    "\n",
    "so for weights we can always use .grad to check the gradients, also putting model.train will set the requrires_grad \n",
    "param to true automatically for the model \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ GRADIENT DESCCENT WITH AUTOGRAD AND BACKPROP ##################################\n",
    "\n",
    "3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################3 training pipeline model loss and optimizer #####################################\n",
    "\n",
    "optimizers like sgd requires parameters as a list \n",
    "\n",
    "\n",
    "training pipeline \n",
    "\n",
    "1. design a model (inputl output and forward pass)\n",
    "2. define loss and optimizer \n",
    "3. make a training loop \n",
    "    forward pass \n",
    "    backward pass \n",
    "    update weights \n",
    "    \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = False)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters = 100 # epochs \n",
    "\n",
    "# define loss \n",
    "loss = nn.MSEloss()\n",
    "\n",
    "# define optimizer \n",
    "optim = torch.optim.SGD([w], lr = learning_rate)\n",
    "\n",
    "\n",
    "# training loop \n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    # forward pass \n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    # compute losss \n",
    "    l = loss(y_pred, Y)\n",
    "    \n",
    "    # calculate gradients \n",
    "    l.backward()\n",
    "    \n",
    "    # update the weights \n",
    "    optim.step()\n",
    "    \n",
    "    # zero the gradients \n",
    "    optim.zero_grad()\n",
    "    \n",
    "    # print information \n",
    "    print(f'epoch : {epoch} : W : {w:.3f} : loss = {l:.5f}')\n",
    "    \n",
    "\n",
    "    \n",
    "# to substitute forward passs by nn.Linear \n",
    "input to the model must be now (batch_size/samples , dim)\n",
    "\n",
    "so reshape X as input to :\n",
    "    torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
    "    and same for Y \n",
    "\n",
    "n_samples, n_features = X.shape   \n",
    "    \n",
    "input_features = n_features \n",
    "output_features = n_features \n",
    "model = nn.Linear(input_features, output_features)\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# define a class for the model \n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(input_dim=input_features, output_dim=output_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [100 x 1], m2: [100 x 1] at /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-35769c6158b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stereo_project/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stereo_project/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/stereo_project/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [100 x 1], m2: [100 x 1] at /opt/conda/conda-bld/pytorch_1595629403081/work/aten/src/TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "##################################   LINEAR REGRESSION ##############################################\n",
    "\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets \n",
    "\n",
    "# generate and prepare data \n",
    "x, y = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "x_tensor = torch.from_numpy(x.astype(np.float32))\n",
    "y_tensor = torch.from_numpy(y.astype(np.float32))\n",
    "y_tensor = y_tensor.view(y_tensor.shape[0],1)\n",
    "\n",
    "n_samples, n_features = x_tensor.shape\n",
    "\n",
    "\n",
    "input_features = n_samples\n",
    "out_size = 1\n",
    "\n",
    "# define model\n",
    "model = nn.Linear(input_features, out_size)\n",
    "\n",
    "# define loss and optimizer \n",
    "loss = nn.MSELoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# train the model \n",
    "n_epochs = 100\n",
    "\n",
    "for epochs in range(n_epochs):\n",
    "    \n",
    "    # forward pass \n",
    "    output = model(x_tensor)\n",
    "    \n",
    "    # calculate loss \n",
    "    loss = loss(output, y_tensor)\n",
    "    \n",
    "    # calculate gradients \n",
    "    loss.backward()\n",
    "    \n",
    "    # update weights \n",
    "    optim.step()\n",
    "    \n",
    "    # zero grads \n",
    "    optim.zero_grad()\n",
    "    \n",
    "    # print info \n",
    "    if (epochs+1)%10 == 0:\n",
    "        print(f'epoch : {epochs}, Loss = {loss.item():.4f}')\n",
    "        \n",
    "        \n",
    "# print the model predictions \n",
    "predictions = model(x_tensor).detach().numpy()\n",
    "\n",
    "plt.plot(x,y,'ro')\n",
    "plt.plot(x,predictions,'b')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################    LOGISTIC REGRESSION #############################################33\n",
    "\n",
    "\n",
    "for logistic regression pass the output of the linear layer into sigmoid funtion (torch.sigmoid) \n",
    "for loss function use the nn.BCELoss binary cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### DATASET AND DATALOADER #######################################\n",
    "\n",
    "# for csv files contains the header then we can skip the header using the arhument skiprows=1 in the np.loadtxt func\n",
    "\n",
    "# for transform we have to pass the transform while initializing the dataset class  \n",
    "\n",
    "import torch \n",
    "import numpy as np \n",
    "import torchvision \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import math \n",
    "\n",
    "# custom dataset class \n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        dataframe = np.loadtxt(\"dada.csv\", delimiter=\",\", skiprows=1, dtype=np.float32)\n",
    "        self.y = torch.from_numpy(dataframe[:,[0]]) # nsamples,1\n",
    "        self.x = torch.from_numpy(dataframe[:,1:])\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return dataframe.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "\n",
    "# create a dataset using the dataset class\n",
    "dataset = WineDataset()\n",
    "\n",
    "total_samples = len(dataset)\n",
    "num_iter = math.ceil(total_samples/batch_size)\n",
    "\n",
    "\n",
    "# create a dataloader using the Dataloader function \n",
    "dataloader = DataLoader(dataset=dataset, batch_size=32, num_workers=4, shuffle = True)\n",
    "\n",
    "# we can use the iter(dataloader) and .next() to get the next batch of data \n",
    "dataiter = iter(dataloader)\n",
    "next_data = dataiter.next()\n",
    "\n",
    "features, labels = next_data\n",
    "    \n",
    "    \n",
    "## or we can use the for loop for iterating over the data \n",
    "\n",
    "for feature, label in dataloader:\n",
    "    # feature is the batch feature \n",
    "    # label is the batch label \n",
    "    \n",
    "    \n",
    "## training loop \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(dataloader):\n",
    "        \n",
    "\n",
    "# pytorch already has prebuilt dataset we can load them from \n",
    "torchvision.datasets.XXX\n",
    "like \n",
    "torchvision.datasets.MNIST()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################3  TRANSFORMS #################################################33\n",
    "\n",
    "# tranforms can be loaded from torchvision.transforms\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "transform = transforms.Compose([Rescale(256),\n",
    "                                RandomCrop(224)])\n",
    "\n",
    "\n",
    "# how to embed it int the dataset class\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None):\n",
    "        \n",
    "        dataframe = np.loadtxt(\"dada.csv\", delimiter=\",\", skiprows=1, dtype=np.float32)\n",
    "        self.y = torch.from_numpy(dataframe[:,[0]]) # nsamples,1\n",
    "        self.x = torch.from_numpy(dataframe[:,1:])\n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return dataframe.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = transform(sample)\n",
    "        return sample \n",
    "\n",
    "\n",
    "# transform available for images\n",
    "CenterCrop, Grayscale, RandomAffine,RandomCrop, RandomRotation, Resize, Scale \n",
    "\n",
    "on tensors \n",
    "Normalize, LinearTransformation\n",
    "\n",
    "conversion \n",
    "ToPILImage\n",
    "ToTensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-857e1e7d0196>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-857e1e7d0196>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    softmax convert the output of the linear layer (scores/logits) into probablities\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##################################3 SOFTMAX AND CROSS ENTROPY ########################################33\n",
    "\n",
    "torch.softmax\n",
    "\n",
    "\n",
    "softmax convert the output of the linear layer (scores/logits) into probablities \n",
    "\n",
    "output = nn.Linear(input)\n",
    "or \n",
    "output = torch.tensor([1,2,3])\n",
    "probablitites = torch.softmax(output, dim=0)\n",
    "\n",
    "\n",
    "softmax is often merged with crossentropy loss in pytorch \n",
    "\n",
    "\n",
    "\n",
    "### cross entropy loss \n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# CrossEntropyLoss = softmax + NLLL loss (negative log likelyhood loss)\n",
    "\n",
    "# works with logits (softmax already inbuilt) so directly feed the output of the linear layer \n",
    "y_pred = output of the linear layer \n",
    "y_actual = must not be one hot encoded, rather it should be a class label \n",
    "\n",
    "loss(predictions, actual_labels)\n",
    "\n",
    "# prediction shape is generally  ->  nsamples, nclasses \n",
    "\n",
    "to get the maximum score use ->  torch.max(predictions, 1)  # 1 specifies the axis so 1 means along the row we are looking \n",
    "\n",
    "\n",
    "for nn.BCELoss we have to use sigmoid in then end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-a278f2d4c0ba>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-a278f2d4c0ba>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    Step funtion\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "####################   ACTIVATION #########################################333\n",
    "\n",
    "Step funtion \n",
    "Sigmoid  (0-1) generalle used as last layer of binary classification problem \n",
    "ReLU  (0 - X) generally used for hidden layers (mostly used)\n",
    "TanH (-1 - 1) usually used in hidden layers \n",
    "Leaky ReLU (-1 - X) used to solve the vanishing gradient problem \n",
    "Softmax used in last layers of multiclass classification problem \n",
    "\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.Functional as F \n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dims, out_dims, hidden_layer):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(in_dims, hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_layer, out_dims)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.relu(y)\n",
    "        y = self.layer2(y)\n",
    "        y = self.sigmoid(y)\n",
    "        \n",
    "        return y \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c54417e9d962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "###############################   FEED FORWARD NEURAL NETWORK #############################3333\n",
    "\n",
    "# Dataloader , Transform, Dataset \n",
    "# network/model, activation \n",
    "# loss, optimizer \n",
    "# training loop \n",
    "# evaluation \n",
    "# GPU \n",
    "\n",
    "\n",
    "### for image the pytorch format is [batchsize/samples, channel, row, col]\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "# set device config \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define hyper parameters \n",
    "in_features = 784\n",
    "hidden_size = 100\n",
    "out_size = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "# LOAD the MNIST dataset \n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", transform=transforms.ToTensor(), download=True, train = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", transform=transforms.ToTensor(), download=True, train = False)\n",
    "\n",
    "\n",
    "# create dataloader for the datset \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# define the model/network \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dims, out_dims, hidden_layer):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(in_dims, hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_layer, out_dims)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.relu(y)\n",
    "        y = self.layer2(y)\n",
    "        return y \n",
    "\n",
    "# load the model \n",
    "model = NeuralNet(in_dims=in_features, out_dims=out_size, hidden_layer=hidden_size)\n",
    "\n",
    "# loss \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer \n",
    "optim = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# train \n",
    "total_steps = len(train_loader)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # forward pass\n",
    "        output = model(images)\n",
    "        \n",
    "        # loss \n",
    "        loss = loss_func(output, labels)\n",
    "        \n",
    "        # gradients update \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        # print info\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch : {epoch+1} / {num_epochs}, step : {i+1} / {total_steps} , loss = {loss.item():.4f}')\n",
    "            \n",
    "            \n",
    "## evaluate the model \n",
    "model.eval()\n",
    "n_samples=0\n",
    "n_correct=0 \n",
    "\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    \n",
    "    images = images.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # output \n",
    "    output = model(images)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    n_samples += labels.shape[0]\n",
    "    n_correct = (preds == labels).sum().item()\n",
    "\n",
    "accuracy = (n_correct/n_samples)*100\n",
    "print(f'accuracy : {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## CNN #################################################3333\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader \n",
    "import torch.nn.fucntional as F \n",
    "\n",
    "\n",
    "# set device config \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define hyper parameters \n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "\n",
    "# LOAD the MNIST dataset \n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", transform=transform, download=True, train = True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", transform=transform, download=True, train = False)\n",
    "\n",
    "# create dataloader for the datset \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= batch_size, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "          'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, out_features):\n",
    "        \n",
    "        self.conv1 = nn.Conv2D(3,6,5)\n",
    "        self.relu = F.relu()\n",
    "        self.conv2 = nn.Conv2D(6,16,5)\n",
    "        self.maxpool = nn.MaxPool2D(2,2)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.maxpool(self.relu(self.conv1(x)))\n",
    "        out = self.maxpool(self.relu(self.conv2(x)))\n",
    "        out = torch.flatten(out)\n",
    "        # out = out.view(-1, 16*5*5)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        return out \n",
    "\n",
    "    \n",
    "    \n",
    "#load the model \n",
    "model = NeuralNet(in_dims=in_features, out_dims=out_size, hidden_layer=hidden_size)\n",
    "\n",
    "# loss \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer \n",
    "optim = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# train \n",
    "total_steps = len(train_loader)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        # forward pass\n",
    "        output = model(images)\n",
    "        \n",
    "        # loss \n",
    "        loss = loss_func(output, labels)\n",
    "        \n",
    "        # gradients update \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        # print info\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch : {epoch+1} / {num_epochs}, step : {i+1} / {total_steps} , loss = {loss.item():.4f}')\n",
    "            \n",
    "            \n",
    "## evaluate the model \n",
    "model.eval()\n",
    "n_samples=0\n",
    "n_correct=0 \n",
    "\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    \n",
    "    images = images.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # output \n",
    "    output = model(images)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    \n",
    "    n_samples += labels.shape[0]\n",
    "    n_correct = (preds == labels).sum().item()\n",
    "\n",
    "accuracy = (n_correct/n_samples)*100\n",
    "print(f'accuracy : {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################   TRANSFER LEARNING ##############################################3\n",
    "\n",
    "import torch.optim as optim \n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import lr_scheduler \n",
    "\n",
    "\n",
    "\n",
    "# create transforms \n",
    "\n",
    "\n",
    "# load datasets for pretrained resnet18 using ImageFolder \n",
    "\n",
    "data_path = \"...\"\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_path,x), transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.Dataloader(image_datasets[x], shuffle=True, batch_size=4, num_workers=2)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "# get the class names \n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "\n",
    "# load the pretrained model \n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "features = model.fc.in_features\n",
    "model.fc = nn.Linear(features, 2)\n",
    "model.to(device)\n",
    "\n",
    "# loss \n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# optim \n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# schedule Lr\n",
    "step_lr_decay = lr_scheduler.StepLR(optim, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################  TENSORBOARD ################################33\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"runs/run1\")\n",
    "\n",
    "writer.add_scalar(\"variable name\", variable)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-c26f9e0fa4a8>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-c26f9e0fa4a8>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    \"optimizer state dict\" : optim.state_dict()\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "###########################################   SAVING AND LOADOING MODELS #####################333333\n",
    "\n",
    "torch.save(arg, PATH)\n",
    "torch.load(PATH)\n",
    "model.load_state_dict(arg)\n",
    "\n",
    "\n",
    "\n",
    "# the reccomended and easy way to save a model \n",
    "\n",
    "\n",
    "# saving \n",
    "torch.save({\n",
    "    \"model_name\" : model_name,\n",
    "    \"state_dict\" : model.state_dict(),\n",
    "    \"info\" : info,\n",
    "    \"exp_config\" : exp_config\n",
    "    \"optimizer state dict\" : optim.state_dict()\n",
    "}, PATH)\n",
    "\n",
    "# loading \n",
    "\n",
    "model = # initialize the model \n",
    "model.load_state_dict(torch.load(PATH)[\"state_dict\"])\n",
    "\n",
    "model.eval()/model.train()\n",
    "\n",
    "\n",
    "for loading the model / checkpoint / state dict on different device use this \n",
    "\n",
    "model.load_state_dict(torch.load(PATH), map_location = device)\n",
    "\n",
    "device = torch.device(\"cuda\") or torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data augmentation using input transform \n",
    "\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########3 LOAD PRETRAINED MODELS \n",
    "\n",
    "import torchvision.models as models \n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "squeezenet = models.squeezenet(pretrained=True)\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### building the model usign sequential function \n",
    "\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1000, 512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(p=0.25),\n",
    "                      \n",
    "                        )\n",
    "\n",
    "#  for binary classification \n",
    "model = nn.Sequential(nn.Linear(1000, 1),\n",
    "                      nn.Sigmoid()\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### normalize for imagenet \n",
    "\n",
    "normalize = transforms.Normalize([0.485,0.456,0.406],\n",
    "                                 [0.229,0.224,0.225])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting intermediate features create a separate class and pass the model, ferature block, classifier block 9into it \n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model, feature_layers, classifier_layers):\n",
    "        super(FeatureExtractor,self).__init__()\n",
    "        self.model = model\n",
    "        self.feature_layers = feature_layers\n",
    "        self.classifier_layers = classifier_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_outputs = []\n",
    "        classifier_outputs = []\n",
    "        # feature modules\n",
    "        for name, module in self.model.features._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.feature_layers:\n",
    "                feature_outputs += [x]\n",
    "        \n",
    "        # avgpool module (used to deal with image size different from 224x224 pixels)\n",
    "        x = self.model.avgpool(x)\n",
    "        x = x.view(x.size(0),-1) # flatten\n",
    "        \n",
    "        # classifier modules\n",
    "        for name, module in self.model.classifier._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.classifier_layers:\n",
    "                classifier_outputs += [x]\n",
    "                \n",
    "        return x, feature_outputs, classifier_outputs\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_module_list = ['1', '4', '9', '16', '23', '30'] # List of modules to inspect\n",
    "classifier_module_list = [] # We will only look at the above feature modules\n",
    "activation_extractor_model = FeatureExtractor(model, feature_module_list, classifier_module_list)\n",
    "activation_extractor_model.eval()\n",
    "with torch.no_grad():\n",
    "    out, y_feat, y_class = activation_extractor_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grayscale image\n",
    "def disp_image(im):\n",
    "    plt.imshow(im, cmap='gray')    \n",
    "\n",
    "    # Remove axis ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "nplot = 3\n",
    "for i in range(nplot):    \n",
    "    plt.subplot(1,nplot,i+1)\n",
    "    disp_image(x[-1,i,:,:])\n",
    "    plt.title('original image, channel %d' % (i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display and showm intermediate features \n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(nplot):    \n",
    "    plt.subplot(1,nplot,i+1)\n",
    "    disp_image(y_feat[indx][-1,i,:,:])\n",
    "    plt.title('feature module %s, channel %d' % (feature_module_list[indx],i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "###############################3   CODE FOR FINE TUNING A RESNET FOR CLASSIFICAITON ##################33333\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "\n",
    "\n",
    "# CREATE TRANSFORMS \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# CREATE DATASETS AND DATALOADERS \n",
    "data_dir = 'data/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "## DISPLAY SOME SAMPLES \n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "\n",
    "## DEFINE THE TRAINING FUNCTION \n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "## VISUALIZE THE MODEL \n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "        \n",
    "        \n",
    "## FINETUNE THE RESNET AND RUN TRAINING \n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE THE CONVNET AS FEATURE EXTRACTOR \n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for params in model.parameters():\n",
    "    params.requires_grad() = False\n",
    "    \n",
    "feature_len = model.fc.in_features\n",
    "model.fc = nn.Linear(feature_len, 2)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
